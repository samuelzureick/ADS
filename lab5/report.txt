Dynamic Programming
===================

Why does the 0/1 Knapsack Problem have the three necessary properties for dynamic programming?

1. Simple Subproblems
As you move through the matrix representing the knapsack problem, you are working with larger and large amounts of items. At the beginning, you are working with a much smaller knapsack, and these solutions can be combined into a larger problem.

2. Subproblem Optimality
If a subproblem works for a smaller knapsack, then it will definitely work on a larger group of items as you work through the algorithm as the capacity is constantly limiting what you are able to put in the knapsack. 

3. Subproblem Overlap
If you find an optimal subproblem, the next iteration of the algorithm will use these previous optimal solutions to find the next optimal solution. The same items will be reused in the knapsack. 


Greedy
======

1.  Why is a greedy approach not necessarily optimal for 0/1 Knapsack?
The greedy approach is not the best solution because it ignores many combinations of items that aren't immediately optimal. There is no backtracking, so once an item is in, it can't be taken out, even if this would lead to a better solution.

2.  Is the greedy approach optimal for the Fractional Knapsack problem?  Explain your reasoning.
The greedy approach is optimal for the fractional knapsack problem, as backtracking is not needed for this. If something doesn't fit, a fraction can be added, and this will happen before the algorithm reaches an item with a worse value to weight ratio because of the ordering of the items.

Testing
=======

1.  Why can't you use full enumeration for large instances?

Suppose one evaluation of a solutions takes 1 microsecond, how large an instance do you think can be practically solved in an hour?  Justify your answer.

2.  Fill in the table below for each test set, noting whether or not you killed the algorithm.  Result should indicate whether the correct optimal solution has been found.  This should be 377 for easy.20.1.txt, 4077 for easy.200.4.txt, 126968 for hard1.200.11.txt and 1205259 for hard1.2000.1.txt.  You can generate this output using test.sh if you wish.

===========================================
easy.20.1.txt 
===========================================
Algorithm |      Optimal Value       | Time Taken  | Result
enum      |      377                 |    12.351s  |  yes  
bnb       |      377                 |    0.086s   |  yes  
dp        |      377                 |    0.206s   |  yes  
greedy    |      101                 |    0.025s   |  ?   
===========================================
easy.200.4.txt
===========================================
Algorithm |      Optimal Value       | Time Taken  | Result
enum      |      394                 | 1m(killed)  |  -  
bnb       |      4077                |    0.086s   |  yes  
dp        |      4077                |    0.206s   |  yes  
greedy    |      1142                |    0.025s   |  ? 

===========================================
hard1.200.11.txt
===========================================
Algorithm |      Optimal Value       | Time Taken  | Result
enum      |      18441               | 1m(killed)  |  -  
bnb       |      126671              |    0.086s   |  no  
dp        |      126968              |    0.206s   |  yes  
greedy    |      112867              |    0.025s   |  ? 

===========================================
hard1.2000.1.txt
===========================================
Algorithm |      Optimal Value       | Time Taken  | Result
enum      |      4021                | 1m(killed)  |  no  
bnb       |      1205173             | 1m(killed)  |  no  
dp        |      -                   | 1m(killed)  |  -  
greedy    |      1053758             |    0.138s   |  ? 


So for instance if you are running the program using the bnb algorithm on the hard1.200.11.txt and kill the program after it has been running for 1 minute and the best solution at that point has 126756 in the knapsack then you should note that you killed the program and write

bnb    126756	1 min  incorrect (killed)

If on the other hand you were running the program using the bnb algorithm on the easy.20.1.txt and it completed after 1 second with a value of 377 then you should write

bnb    377	1 second correct 

Note that some knapsack implementations generate candidate solutions as they go so you can get the program to print its current best solution, while other implementations do not produce a candidate solution until the end.


3.  Which instances does greedy solve optimally?
 Greedy doesn't solve any instances optimally.

Does dynamic programming work on all instances and why/why not?
Dynamic programming does not work on all instances, I think because the matrix that it makes it massive and ends up using up all of the ram that I have allocated. 

Does branch-and-bound come to a stop on all instances in reasonable time?
No it does not, for the 2nd hard solution, it takes an extremely long time.

4.  Can you explain WHY the hard1 instances are easy or hard (cause problems) for
    i) greedy
    ii) branch-and-bound
    iii) dynamic programming

    hard is easy for greedy because all it has to do it sort the items and run until it finds all of the solutions.
    Hard is hard for branch-and-bound because it ends up having such a massive tree and queue of items, as there end up being 2^200/ 2^2000 different combinations of elements. It doesn't have to go through all of them, but there are many similar items with small differences that it will have to filter through.
    Hard1 is easy for dynamic programming because it really effectively breaks down the problem into subproblems and the correct answers end up bubbling down to the end quickly. Each previous step makes the next step a bit easier, unlike bnb which has to backtrack.


5.  The airline has problems of size 500-2000 of similar type to the hard1 instances.  Which algorithms do you recommend using and why?
I would recommend using branch and bound and dynamic programming- they are mostly likely to find optimal solutions in a short amount of time. The greedy algorithm works well, but does not find the optimal solution most of the time.

What should they do in the case the algorihm runs out of time?
If the algorithm runs out of time, they should split the data into two sets, halve the capacity, and then run try again with smaller instances.


